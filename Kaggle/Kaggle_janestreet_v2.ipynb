{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TgIq_BwdwTR",
        "outputId": "3b21adee-68d3-40ff-b440-31c9740600ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ8S_gVId_9J",
        "outputId": "6d0f2a1a-07dc-4918-ccb3-00ac6dfb482d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l55gL4dd7Xb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "with open(\"/content/drive/MyDrive/kaggle.json\", 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "os.environ['KAGGLE_KEY'] = json_data['key']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dltVRKrd7hK",
        "outputId": "ece252b5-7928-470d-dfcd-f305f6f15c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading jane-street-real-time-market-data-forecasting.zip to /content\n",
            "100% 11.4G/11.5G [00:47<00:00, 256MB/s]\n",
            "100% 11.5G/11.5G [00:47<00:00, 260MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c jane-street-real-time-market-data-forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbSVX34AdwyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0aefc68-cc8a-4b42-c13a-6324a97b3364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  jane-street-real-time-market-data-forecasting.zip\n",
            "  inflating: features.csv            \n",
            "  inflating: kaggle_evaluation/__init__.py  \n",
            "  inflating: kaggle_evaluation/core/__init__.py  \n",
            "  inflating: kaggle_evaluation/core/base_gateway.py  \n",
            "  inflating: kaggle_evaluation/core/generated/__init__.py  \n",
            "  inflating: kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py  \n",
            "  inflating: kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py  \n",
            "  inflating: kaggle_evaluation/core/kaggle_evaluation.proto  \n",
            "  inflating: kaggle_evaluation/core/relay.py  \n",
            "  inflating: kaggle_evaluation/core/templates.py  \n",
            "  inflating: kaggle_evaluation/jane_street_gateway.py  \n",
            "  inflating: kaggle_evaluation/jane_street_inference_server.py  \n",
            "  inflating: lags.parquet/date_id=0/part-0.parquet  \n",
            "  inflating: responders.csv          \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.parquet/date_id=0/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=0/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=1/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=2/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=3/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=4/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=5/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=6/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=7/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=8/part-0.parquet  \n",
            "  inflating: train.parquet/partition_id=9/part-0.parquet  \n"
          ]
        }
      ],
      "source": [
        "!unzip jane-street-real-time-market-data-forecasting.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoSLCYs2dwzw",
        "outputId": "c34916d2-9deb-4ac1-be16-c77cc9ef5e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: xgboost 2.1.2\n",
            "Uninstalling xgboost-2.1.2:\n",
            "  Successfully uninstalled xgboost-2.1.2\n",
            "Collecting xgboost==1.6.1\n",
            "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost==1.6.1) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost==1.6.1) (1.13.1)\n",
            "Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.9/192.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "Successfully installed xgboost-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y xgboost\n",
        "!pip install xgboost==1.6.1  # GPUサポートが安定しているバージョンにダウングレード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgwvkO6GT9gz",
        "outputId": "a93873f8-9dfc-4a32-c6f9-6fe647bc4795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "!pip install polars\n",
        "!pip install lightgbm\n",
        "\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import joblib\n",
        "import gc\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import kaggle_evaluation.jane_street_inference_server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "Ki0zj3fKYRYm",
        "outputId": "87ec64b9-0b36-4164-814b-993e127082da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 79)\n",
              "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
              "│ feature_0 ┆ feature_0 ┆ feature_0 ┆ feature_0 ┆ … ┆ feature_7 ┆ feature_7 ┆ feature_7 ┆ feature_ │\n",
              "│ 0         ┆ 1         ┆ 2         ┆ 3         ┆   ┆ 5         ┆ 6         ┆ 7         ┆ 78       │\n",
              "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
              "│ f32       ┆ f32       ┆ f32       ┆ f32       ┆   ┆ f32       ┆ f32       ┆ f32       ┆ f32      │\n",
              "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
              "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ -0.212804 ┆ -0.1807   ┆ 0.245105  ┆ 0.372971 │\n",
              "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ -0.267972 ┆ -0.253485 ┆ -0.147347 ┆ -0.16696 │\n",
              "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 4        │\n",
              "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ -0.476703 ┆ -0.373956 ┆ -0.356012 ┆ -0.35281 │\n",
              "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ -0.339679 ┆ -0.301338 ┆ -0.323033 ┆ -0.23971 │\n",
              "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6        │\n",
              "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ -0.497245 ┆ -0.320908 ┆ -0.486542 ┆ -0.44285 │\n",
              "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9        │\n",
              "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 79)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>&hellip;</th><th>feature_42</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th></tr><tr><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.020184</td><td>0.192278</td><td>0.065021</td><td>-0.347026</td><td>64</td><td>6</td><td>376</td><td>-0.064175</td><td>-0.367097</td><td>0.000438</td><td>-0.385349</td><td>-0.47505</td><td>-0.409575</td><td>-1.361472</td><td>1.181357</td><td>-0.183469</td><td>null</td><td>0.888973</td><td>0.125289</td><td>-0.920569</td><td>0.531765</td><td>null</td><td>null</td><td>1.277653</td><td>-0.526081</td><td>-0.449444</td><td>null</td><td>0.193946</td><td>0.779264</td><td>0.203639</td><td>0.254882</td><td>0.829842</td><td>&hellip;</td><td>1.082042</td><td>-0.679178</td><td>-0.092983</td><td>-0.016576</td><td>0.48</td><td>0.555043</td><td>-0.33077</td><td>-0.200343</td><td>-0.248864</td><td>-0.532577</td><td>-1.591908</td><td>-0.252836</td><td>0.322998</td><td>-0.567509</td><td>0.923749</td><td>-0.38469</td><td>0.427977</td><td>-0.078065</td><td>-0.245995</td><td>0.300441</td><td>0.770848</td><td>-0.301014</td><td>0.458725</td><td>0.103956</td><td>0.826847</td><td>-0.136092</td><td>-0.192107</td><td>-0.044648</td><td>0.10291</td><td>-0.370744</td><td>0.071086</td><td>0.566694</td><td>0.403683</td><td>-0.212804</td><td>-0.1807</td><td>0.245105</td><td>0.372971</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.028087</td><td>0.287438</td><td>0.118074</td><td>-0.644495</td><td>4</td><td>3</td><td>11</td><td>3.419741</td><td>0.997164</td><td>1.706084</td><td>-0.318914</td><td>-0.461119</td><td>-0.294792</td><td>1.929656</td><td>1.213011</td><td>1.16521</td><td>null</td><td>3.431933</td><td>0.792091</td><td>-0.961323</td><td>0.197048</td><td>null</td><td>null</td><td>0.258624</td><td>-0.538528</td><td>-0.306105</td><td>null</td><td>0.12894</td><td>-0.022014</td><td>0.749626</td><td>0.547256</td><td>1.428185</td><td>&hellip;</td><td>-0.712776</td><td>1.209243</td><td>-0.337086</td><td>-0.205467</td><td>-2.51014</td><td>-1.281748</td><td>-0.383061</td><td>0.99984</td><td>1.178574</td><td>-1.942191</td><td>0.445592</td><td>-1.414607</td><td>-1.362255</td><td>-0.760373</td><td>-0.199131</td><td>-2.412528</td><td>-1.033167</td><td>-2.285751</td><td>0.406769</td><td>0.300441</td><td>-0.072687</td><td>0.114416</td><td>0.200983</td><td>2.923207</td><td>1.137057</td><td>5.132564</td><td>0.726686</td><td>1.304514</td><td>3.247437</td><td>0.631181</td><td>2.437627</td><td>-0.341539</td><td>-0.360914</td><td>-0.267972</td><td>-0.253485</td><td>-0.147347</td><td>-0.166964</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.022584</td><td>0.442352</td><td>0.140746</td><td>-0.571057</td><td>81</td><td>2</td><td>534</td><td>0.385333</td><td>0.732816</td><td>0.155896</td><td>0.202543</td><td>0.930962</td><td>0.721754</td><td>-0.865098</td><td>0.108584</td><td>-0.640984</td><td>null</td><td>-0.876378</td><td>-1.044793</td><td>-1.282868</td><td>-0.355638</td><td>null</td><td>null</td><td>0.776003</td><td>-0.126703</td><td>0.290924</td><td>null</td><td>-0.123493</td><td>0.995562</td><td>-0.466438</td><td>-0.349856</td><td>-0.892137</td><td>&hellip;</td><td>1.439713</td><td>2.302129</td><td>2.046488</td><td>0.117269</td><td>-0.105732</td><td>0.343813</td><td>-0.132489</td><td>0.081151</td><td>0.247478</td><td>1.210106</td><td>0.012775</td><td>-0.743068</td><td>0.18959</td><td>0.866432</td><td>0.588312</td><td>-0.599171</td><td>0.269633</td><td>0.248799</td><td>0.33105</td><td>0.300441</td><td>1.796084</td><td>2.408884</td><td>1.916744</td><td>0.658252</td><td>0.340445</td><td>0.652627</td><td>-0.216905</td><td>-0.185448</td><td>0.521877</td><td>1.35906</td><td>0.494098</td><td>-0.20115</td><td>-0.289628</td><td>-0.476703</td><td>-0.373956</td><td>-0.356012</td><td>-0.35281</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.024804</td><td>0.420692</td><td>0.136259</td><td>-0.809642</td><td>11</td><td>7</td><td>76</td><td>-0.200244</td><td>-0.409379</td><td>-0.185599</td><td>0.234811</td><td>0.160243</td><td>0.110508</td><td>-0.959411</td><td>1.392733</td><td>2.161604</td><td>null</td><td>-0.219788</td><td>-0.040412</td><td>-1.940056</td><td>-0.637217</td><td>null</td><td>null</td><td>0.481473</td><td>-0.211353</td><td>0.417266</td><td>null</td><td>-0.111355</td><td>0.543678</td><td>0.090486</td><td>-0.336618</td><td>1.615937</td><td>&hellip;</td><td>0.210434</td><td>-0.663065</td><td>-0.184241</td><td>0.453498</td><td>-0.814056</td><td>0.076486</td><td>0.384369</td><td>0.880885</td><td>0.198965</td><td>1.093185</td><td>1.355752</td><td>0.86659</td><td>-0.543416</td><td>-0.557341</td><td>1.018626</td><td>-0.53542</td><td>-0.299109</td><td>-0.135551</td><td>0.302495</td><td>0.300441</td><td>1.178458</td><td>1.963925</td><td>2.115989</td><td>2.300967</td><td>1.213972</td><td>-0.375353</td><td>-0.315288</td><td>-0.377317</td><td>-0.018499</td><td>-0.303676</td><td>0.042694</td><td>-0.304563</td><td>-0.274469</td><td>-0.339679</td><td>-0.301338</td><td>-0.323033</td><td>-0.239716</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.016138</td><td>0.303561</td><td>0.14997</td><td>-0.727993</td><td>42</td><td>5</td><td>150</td><td>0.089536</td><td>-0.318639</td><td>0.229737</td><td>-0.359855</td><td>-0.135196</td><td>-0.361641</td><td>-1.061814</td><td>1.642337</td><td>0.124642</td><td>null</td><td>-0.523115</td><td>-0.88477</td><td>-1.407083</td><td>-0.564234</td><td>null</td><td>null</td><td>1.599255</td><td>-0.414362</td><td>-0.21513</td><td>null</td><td>-0.042788</td><td>-0.010577</td><td>0.227581</td><td>-0.202145</td><td>-0.719912</td><td>&hellip;</td><td>1.309015</td><td>0.680563</td><td>0.854657</td><td>1.16664</td><td>1.677758</td><td>0.523151</td><td>-0.28115</td><td>0.002627</td><td>1.15112</td><td>0.002777</td><td>0.034642</td><td>0.414592</td><td>0.217866</td><td>-0.189608</td><td>1.401886</td><td>0.302604</td><td>0.711625</td><td>-0.181922</td><td>0.214608</td><td>0.300441</td><td>0.255725</td><td>0.576029</td><td>0.445959</td><td>-0.53101</td><td>1.331284</td><td>0.162807</td><td>-0.20295</td><td>0.06306</td><td>0.219878</td><td>-0.271476</td><td>0.315763</td><td>-0.519676</td><td>-0.716094</td><td>-0.497245</td><td>-0.320908</td><td>-0.486542</td><td>-0.442859</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# パーケットファイルを読み込み、フィルタリングと必要な処理を行う\n",
        "df = pl.scan_parquet(\"train.parquet\")\n",
        "df = df.filter(pl.col(\"partition_id\") == 0).collect()\n",
        "df = df.with_columns(pl.col('responder_6').shift(1).alias('responder_6_lag1'))\n",
        "df = df.with_columns(pl.col('responder_6').shift(2).alias('responder_6_lag2'))\n",
        "df = df.slice(0, len(df) - 1)\n",
        "\n",
        "# 目的変数と特徴量の定義\n",
        "TARGET = 'responder_6'\n",
        "FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "RES_FEAT_COLS = [f\"responder_{i}\" for i in range(9)]\n",
        "LAG_RES_FEAT_COLS = ['responder_6_lag1','responder_6_lag2']\n",
        "\n",
        "# 列を結合して、'responder_6' を除く\n",
        "#COLS = FEAT_COLS + RES_FEAT_COLS + LAG_RES_FEAT_COLS\n",
        "COLS = [x for x in FEAT_COLS if x != TARGET]\n",
        "\n",
        "df[COLS].tail()  # 確認のため出力"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr9lsOKSnvd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw2_L1-ldw2z"
      },
      "outputs": [],
      "source": [
        "# # インストール\n",
        "# !pip install kaggle\n",
        "# import os\n",
        "# import json\n",
        "# with open(\"/content/drive/MyDrive/kaggle.json\", 'r') as f:\n",
        "#     json_data = json.load(f)\n",
        "# os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "# os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "# !kaggle competitions download -c jane-street-real-time-market-data-forecasting\n",
        "# !unzip jane-street-real-time-market-data-forecasting.zip\n",
        "# !pip uninstall -y xgboost\n",
        "# !pip install xgboost==1.6.1  # GPUサポートが安定しているバージョンにダウングレード\n",
        "# !pip install polars\n",
        "# !pip install lightgbm\n",
        "\n",
        "# import numpy as np\n",
        "# import polars as pl\n",
        "# import pandas as pd\n",
        "# import lightgbm as lgb\n",
        "# import xgboost as xgb\n",
        "# import os\n",
        "# import joblib\n",
        "# import gc\n",
        "# from sklearn.model_selection import TimeSeriesSplit\n",
        "# import kaggle_evaluation.jane_street_inference_server\n",
        "\n",
        "# データの読み込み\n",
        "df = pl.scan_parquet(\"train.parquet\")\n",
        "df = df.with_columns(pl.col('responder_6').shift(1).alias('responder_6_lag1'))\n",
        "df = df.with_columns(pl.col('responder_6').shift(2).alias('responder_6_lag2'))\n",
        "\n",
        "# 目的変数と特徴量の定義\n",
        "TARGET = 'responder_6'\n",
        "FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "RES_FEAT_COLS = [f\"responder_{i}\" for i in range(9)]\n",
        "LAG_RES_FEAT_COLS = ['responder_6_lag1','responder_6_lag2']\n",
        "COLS = FEAT_COLS + RES_FEAT_COLS + LAG_RES_FEAT_COLS\n",
        "COLS = [x for x in COLS if x != TARGET]\n",
        "\n",
        "# フィルタリングを通してParquet ファイルからデータをロード\n",
        "def load_data(date_id_range=None, time_id_range=None, columns=None, return_type='pl'):\n",
        "    # parquet形式 : テキスト形式では閲覧できない形式であるがcsvファイルより軽量化され、分析を行う際も高速になる\n",
        "    data = pl.scan_parquet(\"train.parquet\")\n",
        "    data = df.with_columns(pl.col('responder_6').shift(1).alias('responder_6_lag1'))\n",
        "    data = df.with_columns(pl.col('responder_6').shift(2).alias('responder_6_lag2'))\n",
        "\n",
        "    # date_id_rangeが指定されていれば、開始日と終了日を基にdate_idカラムでデータをフィルタリング\n",
        "    if date_id_range:\n",
        "        start_date, end_date = date_id_range\n",
        "        data = data.filter((pl.col(\"date_id\") >= start_date) & (pl.col(\"date_id\") <= end_date))\n",
        "\n",
        "    # time_id_rangeが指定されている場合は、開始時間と終了時間でtime_idカラムをフィルタリング\n",
        "    if time_id_range:\n",
        "        start_time, end_time = time_id_range\n",
        "        data = data.filter((pl.col(\"time_id\") >= start_time) & (pl.col(\"time_id\") <= end_time))\n",
        "\n",
        "    # columnsが指定されている場合、そのカラムだけを選択してデータを絞り込み\n",
        "    if columns:\n",
        "        data = data.select(columns)\n",
        "\n",
        "    # お好みで(polarsの方が早い)\n",
        "    if return_type == 'pd':\n",
        "        return data.collect().to_pandas()\n",
        "    else:\n",
        "        return data.collect()\n",
        "\n",
        "# 重み付きR2スコアを出力\n",
        "def calculate_r2(y_true, y_pred, weights):\n",
        "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
        "    denominator = np.sum(weights * (y_true ** 2))\n",
        "    return 1 - (numerator / denominator)\n",
        "\n",
        "# XGBoostのカスタム損失関数\n",
        "def weighted_squared_error(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    weights = dtrain.get_weight()\n",
        "    errors = preds - labels\n",
        "    gradient = 2 * weights * errors\n",
        "    hessian = 2 * weights\n",
        "    return gradient, hessian\n",
        "\n",
        "# RMSEの計算\n",
        "def weighted_rmse(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    weights = dtrain.get_weight()\n",
        "    weighted_mse = np.sum(weights * (preds - labels) ** 2) / np.sum(weights)\n",
        "    return \"weighted_rmse\", np.sqrt(weighted_mse)\n",
        "\n",
        "# 評価関数\n",
        "def evaluate_model(model, test_data):\n",
        "    y_pred = model.predict(test_data[COLS])\n",
        "    y_true = test_data[TARGET].to_numpy()\n",
        "    weights = test_data['weight'].to_numpy()\n",
        "    r2_score = calculate_r2(y_true, y_pred, weights)\n",
        "    print(f\"Sample weighted zero-mean R-squared score (R2) on test data: {r2_score}\")\n",
        "\n",
        "# 複数のモデルを一つのオブジェクトにまとめることで、後に予測時に平均化などを行うための土台を作る\n",
        "class ModelGroup:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "\n",
        "    # モデルを追加\n",
        "    def add_model(self, model):\n",
        "        self.models.append(model)\n",
        "\n",
        "    # 学習した各モデルから予測値を作成\n",
        "    def predict(self, test_data):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            if isinstance(model, lgb.Booster):\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            elif isinstance(model, xgb.Booster):\n",
        "                pred = model.predict(xgb.DMatrix(test_data[FEAT_COLS]))\n",
        "            elif hasattr(model, 'predict'):\n",
        "                pred = model.predict(test_data[FEAT_COLS]) # For PyTorch or other model\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model type\")\n",
        "            preds.append(pred)\n",
        "\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file_path):\n",
        "        return joblib.load(file_path)\n",
        "\n",
        "# XGboostモデルの定義\n",
        "def train_xgb_kfold(total_days=1498, n_splits=5, save_models=True, num_boost_round=500):\n",
        "    # 目的変数と特徴量の定義\n",
        "    TARGET = 'responder_6'\n",
        "    FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "    RES_FEAT_COLS = [f\"responder_{i}\" for i in range(9)]\n",
        "    LAG_RES_FEAT_COLS = ['responder_6_lag1','responder_6_lag2']\n",
        "    COLS = FEAT_COLS + RES_FEAT_COLS + LAG_RES_FEAT_COLS\n",
        "    COLS = [x for x in COLS if x != TARGET]\n",
        "\n",
        "    # 時系列の分割\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits, max_train_size=50000) #メモリの都合によりサイズを調整\n",
        "\n",
        "    # インスタンス作成\n",
        "    model_group = ModelGroup()\n",
        "    model = None\n",
        "\n",
        "    # 分割データの中で訓練データと評価データに分割\n",
        "    for fold_idx, (train_index, valid_index) in enumerate(tscv.split(range(total_days))):\n",
        "        sampled_train_index = train_index[:int(0.8 * len(train_index))]\n",
        "        train_range = (sampled_train_index[0], sampled_train_index[-1])\n",
        "        valid_range = (valid_index[0], valid_index[-1])\n",
        "\n",
        "        # 評価データの作成\n",
        "        valid_data = load_data(date_id_range=valid_range, columns=[\"date_id\", \"weight\"] + COLS + [TARGET], return_type='pl')\n",
        "        valid_data = valid_data.with_columns([pl.col(c).cast(pl.Float32) for c in COLS + [TARGET, \"weight\"]]) #データをFloat32にキャスト\n",
        "\n",
        "        # 検証データの重みとラベルを xgboost.DMatrix 形式に変換\n",
        "        valid_weight = valid_data['weight'].to_numpy()\n",
        "        dvalid = xgb.DMatrix(valid_data.select(COLS).to_pandas(), label=valid_data[TARGET].to_pandas(), weight=valid_weight)\n",
        "\n",
        "        # バッチサイズの指定\n",
        "        batch_size = 500 if fold_idx == n_splits - 1 else 2000  # 最後のfoldは小さなバッチサイズ\n",
        "\n",
        "        # 学習データの作成\n",
        "        for train_idx in range(train_range[0], train_range[1], batch_size):\n",
        "            end_idx = min(train_idx + batch_size - 1, train_range[1])\n",
        "            partial_train_data = load_data(date_id_range=(train_idx, end_idx), columns=[\"date_id\", \"weight\"] + COLS + [TARGET], return_type='pl')\n",
        "            partial_train_data = partial_train_data.with_columns([pl.col(c).cast(pl.Float32) for c in COLS + [TARGET, \"weight\"]])\n",
        "            train_weight = partial_train_data['weight'].to_numpy()\n",
        "            dtrain = xgb.DMatrix(partial_train_data.select(COLS).to_pandas(), label=partial_train_data[TARGET].to_pandas(), weight=train_weight)\n",
        "\n",
        "            # パラメータ設定\n",
        "            XGB_PARAMS = {\n",
        "                'objective': 'reg:squarederror',\n",
        "                'learning_rate': 0.03,\n",
        "                'max_depth': 3,\n",
        "                'min_child_weight': 3,\n",
        "                'subsample': 0.7,\n",
        "                'colsample_bytree': 0.7,\n",
        "                'random_state': 42,\n",
        "                'tree_method': 'gpu_hist',\n",
        "            }\n",
        "\n",
        "            model = xgb.train(\n",
        "                XGB_PARAMS,\n",
        "                dtrain,\n",
        "                num_boost_round=num_boost_round,\n",
        "                xgb_model=model,\n",
        "                evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
        "                early_stopping_rounds=50,\n",
        "                verbose_eval=50,\n",
        "                obj=weighted_squared_error,\n",
        "                custom_metric=weighted_rmse\n",
        "            )\n",
        "\n",
        "            # 余計なものは削除\n",
        "            del partial_train_data, dtrain, train_weight\n",
        "            gc.collect()\n",
        "\n",
        "        # R2を計算\n",
        "        y_valid_pred = model.predict(dvalid)\n",
        "        r2_score = calculate_r2(valid_data[TARGET].to_numpy(), y_valid_pred, valid_weight)\n",
        "        print(f\"Fold {fold_idx} validation R2 score: {r2_score}\")\n",
        "\n",
        "        model_group.add_model(model)\n",
        "\n",
        "        if save_models:\n",
        "            joblib.dump(model, f\"xgb_model_group_{fold_idx}.pkl\")\n",
        "            print(f\"Saved the model for fold {fold_idx} to xgb_model_group_{fold_idx}.pkl\")\n",
        "\n",
        "        del dvalid, valid_data, valid_weight, y_valid_pred\n",
        "        gc.collect()\n",
        "\n",
        "    return model_group\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HosefnRD8PiS",
        "outputId": "c1faec46-ca19-4a16-e724-3b9154c6419a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.95824\ttrain-weighted_rmse:0.95824\tvalid-rmse:1.00505\tvalid-weighted_rmse:1.00505\n",
            "[50]\ttrain-rmse:0.60902\ttrain-weighted_rmse:0.60902\tvalid-rmse:0.60518\tvalid-weighted_rmse:0.60518\n",
            "[100]\ttrain-rmse:0.52796\ttrain-weighted_rmse:0.52796\tvalid-rmse:0.50113\tvalid-weighted_rmse:0.50113\n",
            "[150]\ttrain-rmse:0.49244\ttrain-weighted_rmse:0.49244\tvalid-rmse:0.45874\tvalid-weighted_rmse:0.45874\n",
            "[200]\ttrain-rmse:0.47021\ttrain-weighted_rmse:0.47020\tvalid-rmse:0.43298\tvalid-weighted_rmse:0.43298\n",
            "[250]\ttrain-rmse:0.45523\ttrain-weighted_rmse:0.45523\tvalid-rmse:0.41735\tvalid-weighted_rmse:0.41735\n",
            "[300]\ttrain-rmse:0.44418\ttrain-weighted_rmse:0.44418\tvalid-rmse:0.40467\tvalid-weighted_rmse:0.40467\n",
            "[350]\ttrain-rmse:0.43591\ttrain-weighted_rmse:0.43591\tvalid-rmse:0.39486\tvalid-weighted_rmse:0.39486\n",
            "[400]\ttrain-rmse:0.42936\ttrain-weighted_rmse:0.42936\tvalid-rmse:0.38706\tvalid-weighted_rmse:0.38706\n",
            "[450]\ttrain-rmse:0.42437\ttrain-weighted_rmse:0.42437\tvalid-rmse:0.38190\tvalid-weighted_rmse:0.38190\n",
            "[499]\ttrain-rmse:0.41968\ttrain-weighted_rmse:0.41968\tvalid-rmse:0.37617\tvalid-weighted_rmse:0.37617\n",
            "Fold 0 validation R2 score: 0.8204084634780884\n",
            "Saved the model for fold 0 to xgb_model_group_0.pkl\n",
            "[0]\ttrain-rmse:0.39974\ttrain-weighted_rmse:0.39974\tvalid-rmse:0.37655\tvalid-weighted_rmse:0.37655\n",
            "[50]\ttrain-rmse:0.38707\ttrain-weighted_rmse:0.38707\tvalid-rmse:0.34562\tvalid-weighted_rmse:0.34562\n",
            "[100]\ttrain-rmse:0.38187\ttrain-weighted_rmse:0.38187\tvalid-rmse:0.33408\tvalid-weighted_rmse:0.33408\n",
            "[150]\ttrain-rmse:0.37763\ttrain-weighted_rmse:0.37763\tvalid-rmse:0.32615\tvalid-weighted_rmse:0.32615\n",
            "[200]\ttrain-rmse:0.37463\ttrain-weighted_rmse:0.37463\tvalid-rmse:0.32153\tvalid-weighted_rmse:0.32153\n",
            "[250]\ttrain-rmse:0.37186\ttrain-weighted_rmse:0.37186\tvalid-rmse:0.31782\tvalid-weighted_rmse:0.31782\n",
            "[300]\ttrain-rmse:0.36977\ttrain-weighted_rmse:0.36977\tvalid-rmse:0.31509\tvalid-weighted_rmse:0.31509\n",
            "[350]\ttrain-rmse:0.36780\ttrain-weighted_rmse:0.36780\tvalid-rmse:0.31258\tvalid-weighted_rmse:0.31258\n",
            "[400]\ttrain-rmse:0.36609\ttrain-weighted_rmse:0.36609\tvalid-rmse:0.31053\tvalid-weighted_rmse:0.31053\n",
            "[450]\ttrain-rmse:0.36470\ttrain-weighted_rmse:0.36470\tvalid-rmse:0.30896\tvalid-weighted_rmse:0.30896\n",
            "[499]\ttrain-rmse:0.36311\ttrain-weighted_rmse:0.36311\tvalid-rmse:0.30721\tvalid-weighted_rmse:0.30721\n",
            "Fold 1 validation R2 score: 0.884078674018383\n",
            "Saved the model for fold 1 to xgb_model_group_1.pkl\n",
            "[0]\ttrain-rmse:0.34549\ttrain-weighted_rmse:0.34549\tvalid-rmse:0.30875\tvalid-weighted_rmse:0.30875\n",
            "[50]\ttrain-rmse:0.34257\ttrain-weighted_rmse:0.34257\tvalid-rmse:0.30342\tvalid-weighted_rmse:0.30342\n",
            "[100]\ttrain-rmse:0.34071\ttrain-weighted_rmse:0.34071\tvalid-rmse:0.29990\tvalid-weighted_rmse:0.29990\n",
            "[150]\ttrain-rmse:0.33925\ttrain-weighted_rmse:0.33925\tvalid-rmse:0.29751\tvalid-weighted_rmse:0.29751\n",
            "[200]\ttrain-rmse:0.33809\ttrain-weighted_rmse:0.33809\tvalid-rmse:0.29543\tvalid-weighted_rmse:0.29543\n",
            "[250]\ttrain-rmse:0.33703\ttrain-weighted_rmse:0.33703\tvalid-rmse:0.29377\tvalid-weighted_rmse:0.29377\n",
            "[300]\ttrain-rmse:0.33619\ttrain-weighted_rmse:0.33619\tvalid-rmse:0.29229\tvalid-weighted_rmse:0.29229\n",
            "[350]\ttrain-rmse:0.33536\ttrain-weighted_rmse:0.33536\tvalid-rmse:0.29097\tvalid-weighted_rmse:0.29097\n",
            "[400]\ttrain-rmse:0.33464\ttrain-weighted_rmse:0.33464\tvalid-rmse:0.29007\tvalid-weighted_rmse:0.29007\n",
            "[450]\ttrain-rmse:0.33404\ttrain-weighted_rmse:0.33404\tvalid-rmse:0.28921\tvalid-weighted_rmse:0.28921\n",
            "[499]\ttrain-rmse:0.33355\ttrain-weighted_rmse:0.33355\tvalid-rmse:0.28852\tvalid-weighted_rmse:0.28852\n",
            "Fold 2 validation R2 score: 0.8960410431027412\n",
            "Saved the model for fold 2 to xgb_model_group_2.pkl\n",
            "[0]\ttrain-rmse:0.32672\ttrain-weighted_rmse:0.32672\tvalid-rmse:0.28052\tvalid-weighted_rmse:0.28052\n",
            "[50]\ttrain-rmse:0.32517\ttrain-weighted_rmse:0.32517\tvalid-rmse:0.27696\tvalid-weighted_rmse:0.27696\n",
            "[100]\ttrain-rmse:0.32429\ttrain-weighted_rmse:0.32428\tvalid-rmse:0.27555\tvalid-weighted_rmse:0.27555\n",
            "[150]\ttrain-rmse:0.32349\ttrain-weighted_rmse:0.32349\tvalid-rmse:0.27418\tvalid-weighted_rmse:0.27418\n",
            "[200]\ttrain-rmse:0.32283\ttrain-weighted_rmse:0.32283\tvalid-rmse:0.27314\tvalid-weighted_rmse:0.27315\n",
            "[250]\ttrain-rmse:0.32232\ttrain-weighted_rmse:0.32232\tvalid-rmse:0.27255\tvalid-weighted_rmse:0.27255\n",
            "[300]\ttrain-rmse:0.32181\ttrain-weighted_rmse:0.32181\tvalid-rmse:0.27181\tvalid-weighted_rmse:0.27181\n",
            "[350]\ttrain-rmse:0.32144\ttrain-weighted_rmse:0.32144\tvalid-rmse:0.27131\tvalid-weighted_rmse:0.27131\n",
            "[400]\ttrain-rmse:0.32108\ttrain-weighted_rmse:0.32108\tvalid-rmse:0.27083\tvalid-weighted_rmse:0.27083\n",
            "[450]\ttrain-rmse:0.32077\ttrain-weighted_rmse:0.32077\tvalid-rmse:0.27051\tvalid-weighted_rmse:0.27051\n",
            "[499]\ttrain-rmse:0.32049\ttrain-weighted_rmse:0.32049\tvalid-rmse:0.27027\tvalid-weighted_rmse:0.27027\n",
            "Fold 3 validation R2 score: 0.9018221646547318\n",
            "Saved the model for fold 3 to xgb_model_group_3.pkl\n",
            "[0]\ttrain-rmse:0.33593\ttrain-weighted_rmse:0.33593\tvalid-rmse:0.32523\tvalid-weighted_rmse:0.32523\n",
            "[50]\ttrain-rmse:0.33526\ttrain-weighted_rmse:0.33526\tvalid-rmse:0.32394\tvalid-weighted_rmse:0.32394\n",
            "[100]\ttrain-rmse:0.33475\ttrain-weighted_rmse:0.33475\tvalid-rmse:0.32322\tvalid-weighted_rmse:0.32322\n",
            "[150]\ttrain-rmse:0.33435\ttrain-weighted_rmse:0.33435\tvalid-rmse:0.32279\tvalid-weighted_rmse:0.32279\n",
            "[200]\ttrain-rmse:0.33404\ttrain-weighted_rmse:0.33404\tvalid-rmse:0.32248\tvalid-weighted_rmse:0.32248\n",
            "[250]\ttrain-rmse:0.33373\ttrain-weighted_rmse:0.33373\tvalid-rmse:0.32257\tvalid-weighted_rmse:0.32257\n",
            "[300]\ttrain-rmse:0.33345\ttrain-weighted_rmse:0.33344\tvalid-rmse:0.32211\tvalid-weighted_rmse:0.32211\n",
            "[350]\ttrain-rmse:0.33321\ttrain-weighted_rmse:0.33321\tvalid-rmse:0.32127\tvalid-weighted_rmse:0.32127\n",
            "[400]\ttrain-rmse:0.33297\ttrain-weighted_rmse:0.33297\tvalid-rmse:0.32089\tvalid-weighted_rmse:0.32089\n",
            "[450]\ttrain-rmse:0.33274\ttrain-weighted_rmse:0.33274\tvalid-rmse:0.32052\tvalid-weighted_rmse:0.32052\n",
            "[488]\ttrain-rmse:0.33259\ttrain-weighted_rmse:0.33259\tvalid-rmse:0.32053\tvalid-weighted_rmse:0.32053\n",
            "[0]\ttrain-rmse:0.27910\ttrain-weighted_rmse:0.27910\tvalid-rmse:0.32047\tvalid-weighted_rmse:0.32048\n",
            "[50]\ttrain-rmse:0.27670\ttrain-weighted_rmse:0.27670\tvalid-rmse:0.32089\tvalid-weighted_rmse:0.32089\n",
            "[74]\ttrain-rmse:0.27603\ttrain-weighted_rmse:0.27603\tvalid-rmse:0.32148\tvalid-weighted_rmse:0.32148\n",
            "Fold 4 validation R2 score: 0.8507829904556274\n",
            "Saved the model for fold 4 to xgb_model_group_4.pkl\n"
          ]
        }
      ],
      "source": [
        "# 実行例\n",
        "total_days = 1498\n",
        "xgb_models = train_xgb_kfold(total_days=total_days, n_splits=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz7gEgIWBbRj"
      },
      "outputs": [],
      "source": [
        "#モデルファイルをドライブから持ってくる\n",
        "import joblib\n",
        "class ModelGroup:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "\n",
        "    def add_model(self, model):\n",
        "        \"\"\"Add a trained model to the group.\"\"\"\n",
        "        self.models.append(model)\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        \"\"\"Make predictions using all models in the group and return the average.\"\"\"\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            if isinstance(model, lgb.Booster):\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            elif isinstance(model, xgb.Booster):\n",
        "                pred = model.predict(xgb.DMatrix(test_data[FEAT_COLS]))\n",
        "            elif hasattr(model, 'predict'):  # For PyTorch or other models\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model type\")\n",
        "\n",
        "            preds.append(pred)\n",
        "\n",
        "        # Average the predictions from all models\n",
        "        avg_pred = np.mean(preds, axis=0)\n",
        "        return avg_pred\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file_path):\n",
        "        \"\"\"Load a model group from a file.\"\"\"\n",
        "        model_group = joblib.load(file_path)\n",
        "        return model_group\n",
        "\n",
        "lgb_model = ModelGroup.load(\"drive/MyDrive/lgb_model_group_v3.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbL99ZqKgcwO",
        "outputId": "5c845339-f40e-4b5a-db1c-47720faa75da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (39, 2)\n",
            "┌────────┬─────────────┐\n",
            "│ row_id ┆ responder_6 │\n",
            "│ ---    ┆ ---         │\n",
            "│ i64    ┆ f64         │\n",
            "╞════════╪═════════════╡\n",
            "│ 0      ┆ -0.010348   │\n",
            "│ 1      ┆ -0.010348   │\n",
            "│ 2      ┆ -0.010348   │\n",
            "│ 3      ┆ -0.010348   │\n",
            "│ 4      ┆ -0.010348   │\n",
            "│ …      ┆ …           │\n",
            "│ 34     ┆ -0.010348   │\n",
            "│ 35     ┆ -0.010348   │\n",
            "│ 36     ┆ -0.011446   │\n",
            "│ 37     ┆ -0.010348   │\n",
            "│ 38     ┆ -0.010348   │\n",
            "└────────┴─────────────┘\n"
          ]
        }
      ],
      "source": [
        "#lags_ というグローバル変数を宣言し、型は Polars データフレームまたは None として定義\n",
        "lags_ : pl.DataFrame | None = None\n",
        "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
        "    \"\"\"Make a prediction.\"\"\"\n",
        "    # lags_ をグローバル変数として使用し、lags が渡されている場合は、lags_ に代入\n",
        "    global lags_\n",
        "    if lags is not None:\n",
        "        lags_ = lags\n",
        "    # test データフレームから row_id 列を選択し、responder_6 列を0で仮埋め\n",
        "    predictions = test.select(\n",
        "        'row_id',\n",
        "        pl.lit(0.0).alias('responder_6'),\n",
        "    )\n",
        "\n",
        "    # 予測値出力\n",
        "    feat = test[FEAT_COLS].to_pandas()\n",
        "    pred = lgb_model.predict(feat)\n",
        "\n",
        "    # 予測値の出力\n",
        "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
        "    print(predictions)\n",
        "\n",
        "    # The predict function must return a DataFrame\n",
        "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
        "    # with columns 'row_id', 'responder_6'\n",
        "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
        "    # and as many rows as the test data.\n",
        "    assert len(predictions) == len(test)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    inference_server.run_local_gateway(\n",
        "        (\n",
        "            'test.parquet',\n",
        "            'lags.parquet',\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejdVG9EXKQbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D9hDFFMeKQeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKD4BqWsKQhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PA-I7ZDNKQj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# インストール\n",
        "!pip install kaggle\n",
        "import os\n",
        "import json\n",
        "!kaggle competitions download -c jane-street-real-time-market-data-forecasting\n",
        "!unzip jane-street-real-time-market-data-forecasting.zip\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import joblib\n",
        "import gc\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import kaggle_evaluation.jane_street_inference_server\n",
        "\n",
        "# 目的変数と特徴量の定義\n",
        "TARGET = 'responder_6'\n",
        "FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "\n",
        "#モデルファイルをドライブから持ってくる\n",
        "import joblib\n",
        "class ModelGroup:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "\n",
        "    def add_model(self, model):\n",
        "        \"\"\"Add a trained model to the group.\"\"\"\n",
        "        self.models.append(model)\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        \"\"\"Make predictions using all models in the group and return the average.\"\"\"\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            if isinstance(model, lgb.Booster):\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            elif isinstance(model, xgb.Booster):\n",
        "                pred = model.predict(xgb.DMatrix(test_data[FEAT_COLS]))\n",
        "            elif hasattr(model, 'predict'):  # For PyTorch or other models\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model type\")\n",
        "\n",
        "            preds.append(pred)\n",
        "\n",
        "        # Average the predictions from all models\n",
        "        avg_pred = np.mean(preds, axis=0)\n",
        "        return avg_pred\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file_path):\n",
        "        \"\"\"Load a model group from a file.\"\"\"\n",
        "        model_group = joblib.load(file_path)\n",
        "        return model_group\n",
        "\n",
        "lgb_model = ModelGroup.load(\"drive/MyDrive/lgb_model_group_v3.pkl\")\n",
        "\n",
        "#lags_ というグローバル変数を宣言し、型は Polars データフレームまたは None として定義\n",
        "lags_ : pl.DataFrame | None = None\n",
        "\n",
        "\n",
        "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
        "    \"\"\"Make a prediction.\"\"\"\n",
        "    # lags_ をグローバル変数として使用し、lags が渡されている場合は、lags_ に代入\n",
        "    global lags_\n",
        "    if lags is not None:\n",
        "        lags_ = lags\n",
        "    # test データフレームから row_id 列を選択し、responder_6 列を0で仮埋め\n",
        "    predictions = test.select(\n",
        "        'row_id',\n",
        "        pl.lit(0.0).alias('responder_6'),\n",
        "    )\n",
        "\n",
        "    # 予測値出力\n",
        "    feat = test[FEAT_COLS].to_pandas()\n",
        "    pred = lgb_model.predict(feat)\n",
        "\n",
        "    # 予測値の出力\n",
        "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
        "    print(predictions)\n",
        "\n",
        "    # The predict function must return a DataFrame\n",
        "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
        "    # with columns 'row_id', 'responder_6'\n",
        "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
        "    # and as many rows as the test data.\n",
        "    assert len(predictions) == len(test)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    inference_server.run_local_gateway(\n",
        "        (\n",
        "            '../input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
        "            '../input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "g0UU6_5VKQmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whH4oEofnozh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# インストール\n",
        "!pip install kaggle\n",
        "!pip install kaggle_evaluation\n",
        "!pip install kaggle_evaluation.jane_street_inference_server\n",
        "import os\n",
        "import json\n",
        "!kaggle competitions download -c jane-street-real-time-market-data-forecasting\n",
        "!unzip jane-street-real-time-market-data-forecasting.zip\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import joblib\n",
        "import gc\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import kaggle_evaluation.jane_street_inference_server\n",
        "\n",
        "# 目的変数と特徴量の定義\n",
        "TARGET = 'responder_6'\n",
        "FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "\n",
        "#モデルファイルをドライブから持ってくる\n",
        "import joblib\n",
        "class ModelGroup:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "\n",
        "    def add_model(self, model):\n",
        "        \"\"\"Add a trained model to the group.\"\"\"\n",
        "        self.models.append(model)\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        \"\"\"Make predictions using all models in the group and return the average.\"\"\"\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            if isinstance(model, lgb.Booster):\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            elif isinstance(model, xgb.Booster):\n",
        "                pred = model.predict(xgb.DMatrix(test_data[FEAT_COLS]))\n",
        "            elif hasattr(model, 'predict'):  # For PyTorch or other models\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model type\")\n",
        "\n",
        "            preds.append(pred)\n",
        "\n",
        "        # Average the predictions from all models\n",
        "        avg_pred = np.mean(preds, axis=0)\n",
        "        return avg_pred\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file_path):\n",
        "        \"\"\"Load a model group from a file.\"\"\"\n",
        "        model_group = joblib.load(file_path)\n",
        "        return model_group\n",
        "\n",
        "lgb_model = ModelGroup.load(\"/kaggle/input/lgb_model_group_v3/other/default/1/lgb_model_group_v3.pkl\")\n",
        "\n",
        "#lags_ というグローバル変数を宣言し、型は Polars データフレームまたは None として定義\n",
        "lags_ : pl.DataFrame | None = None\n",
        "\n",
        "\n",
        "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
        "    \"\"\"Make a prediction.\"\"\"\n",
        "    # lags_ をグローバル変数として使用し、lags が渡されている場合は、lags_ に代入\n",
        "    global lags_\n",
        "    if lags is not None:\n",
        "        lags_ = lags\n",
        "    # test データフレームから row_id 列を選択し、responder_6 列を0で仮埋め\n",
        "    predictions = test.select(\n",
        "        'row_id',\n",
        "        pl.lit(0.0).alias('responder_6'),\n",
        "    )\n",
        "\n",
        "    # 予測値出力\n",
        "    feat = test[FEAT_COLS].to_pandas()\n",
        "    pred = lgb_model.predict(feat)\n",
        "\n",
        "    # 予測値の出力\n",
        "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
        "    print(predictions)\n",
        "\n",
        "    # The predict function must return a DataFrame\n",
        "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
        "    # with columns 'row_id', 'responder_6'\n",
        "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
        "    # and as many rows as the test data.\n",
        "    assert len(predictions) == len(test)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    inference_server.run_local_gateway(\n",
        "        (\n",
        "            '../input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
        "            '../input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "hqSf-xp8no2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# インストール\n",
        "!pip install kaggle\n",
        "import os\n",
        "import json\n",
        "# with open(\"/content/drive/MyDrive/kaggle.json\", 'r') as f:\n",
        "#     json_data = json.load(f)\n",
        "# os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "# os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "!kaggle competitions download -c jane-street-real-time-market-data-forecasting\n",
        "!unzip jane-street-real-time-market-data-forecasting.zip\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import joblib\n",
        "import gc\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import kaggle_evaluation.jane_street_inference_server\n",
        "\n",
        "# 目的変数と特徴量の定義\n",
        "TARGET = 'responder_6'\n",
        "FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "\n",
        "# フィルタリングを通してParquet ファイルからデータをロード\n",
        "def load_data(date_id_range=None, time_id_range=None, columns=None, return_type='pl'):\n",
        "    # parquet形式 : テキスト形式では閲覧できない形式であるがcsvファイルより軽量化され、分析を行う際も高速になる\n",
        "    data_dir = '../input/jane-street-real-time-market-data-forecasting'\n",
        "    # Load data using Polars lazy loading (scan_parquet)\n",
        "    data = pl.scan_parquet(f\"{data_dir}/train.parquet\")\n",
        "\n",
        "    # date_id_rangeが指定されていれば、開始日と終了日を基にdate_idカラムでデータをフィルタリング\n",
        "    if date_id_range:\n",
        "        start_date, end_date = date_id_range\n",
        "        data = data.filter((pl.col(\"date_id\") >= start_date) & (pl.col(\"date_id\") <= end_date))\n",
        "\n",
        "    # time_id_rangeが指定されている場合は、開始時間と終了時間でtime_idカラムをフィルタリング\n",
        "    if time_id_range:\n",
        "        start_time, end_time = time_id_range\n",
        "        data = data.filter((pl.col(\"time_id\") >= start_time) & (pl.col(\"time_id\") <= end_time))\n",
        "\n",
        "    # columnsが指定されている場合、そのカラムだけを選択してデータを絞り込み\n",
        "    if columns:\n",
        "        data = data.select(columns)\n",
        "\n",
        "    # お好みで(polarsの方が早い)\n",
        "    if return_type == 'pd':\n",
        "        return data.collect().to_pandas()\n",
        "    else:\n",
        "        return data.collect()\n",
        "\n",
        "# 重み付きR2スコアを出力\n",
        "def calculate_r2(y_true, y_pred, weights):\n",
        "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
        "    denominator = np.sum(weights * (y_true ** 2))\n",
        "    return 1 - (numerator / denominator)\n",
        "\n",
        "# XGBoostのカスタム損失関数\n",
        "def weighted_squared_error(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    weights = dtrain.get_weight()\n",
        "    errors = preds - labels\n",
        "    gradient = 2 * weights * errors\n",
        "    hessian = 2 * weights\n",
        "    return gradient, hessian\n",
        "\n",
        "# RMSEの計算\n",
        "def weighted_rmse(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    weights = dtrain.get_weight()\n",
        "    weighted_mse = np.sum(weights * (preds - labels) ** 2) / np.sum(weights)\n",
        "    return \"weighted_rmse\", np.sqrt(weighted_mse)\n",
        "\n",
        "# 評価関数\n",
        "def evaluate_model(model, test_data):\n",
        "    y_pred = model.predict(test_data[FEAT_COLS])\n",
        "    y_true = test_data[TARGET].to_numpy()\n",
        "    weights = test_data['weight'].to_numpy()\n",
        "    r2_score = calculate_r2(y_true, y_pred, weights)\n",
        "    print(f\"Sample weighted zero-mean R-squared score (R2) on test data: {r2_score}\")\n",
        "\n",
        "# 複数のモデルを一つのオブジェクトにまとめることで、後に予測時に平均化などを行うための土台を作る\n",
        "class ModelGroup:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "\n",
        "    # モデルを追加\n",
        "    def add_model(self, model):\n",
        "        self.models.append(model)\n",
        "\n",
        "    # 学習した各モデルから予測値を作成\n",
        "    def predict(self, test_data):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            if isinstance(model, lgb.Booster):\n",
        "                pred = model.predict(test_data[FEAT_COLS])\n",
        "            elif isinstance(model, xgb.Booster):\n",
        "                pred = model.predict(xgb.DMatrix(test_data[FEAT_COLS]))\n",
        "            elif hasattr(model, 'predict'):\n",
        "                pred = model.predict(test_data[FEAT_COLS]) # For PyTorch or other model\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model type\")\n",
        "            preds.append(pred)\n",
        "\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file_path):\n",
        "        return joblib.load(file_path)\n",
        "\n",
        "# XGboostモデルの定義\n",
        "def train_xgb_kfold(total_days=1498, n_splits=5, save_models=True, num_boost_round=50):\n",
        "    # 目的変数と特徴量の定義\n",
        "    TARGET = 'responder_6'\n",
        "    FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "\n",
        "    # 時系列の分割\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits, max_train_size=100) #メモリの都合によりサイズを調整\n",
        "\n",
        "    # インスタンス作成\n",
        "    model_group = ModelGroup()\n",
        "    model = None\n",
        "\n",
        "    # 分割データの中で訓練データと評価データに分割\n",
        "    for fold_idx, (train_index, valid_index) in enumerate(tscv.split(range(total_days))):\n",
        "        sampled_train_index = train_index[-int(0.8 * len(train_index)):]\n",
        "        train_range = (sampled_train_index[0], sampled_train_index[-1])\n",
        "        valid_range = (valid_index[0], valid_index[-1])\n",
        "\n",
        "        # 評価データの作成\n",
        "        valid_data = load_data(date_id_range=valid_range, columns=[\"date_id\", \"weight\"] + FEAT_COLS + [TARGET], return_type='pl')\n",
        "        valid_data = valid_data.with_columns([pl.col(c).cast(pl.Float32) for c in FEAT_COLS + [TARGET, \"weight\"]]) #データをFloat32にキャスト\n",
        "\n",
        "        # 検証データの重みとラベルを xgboost.DMatrix 形式に変換\n",
        "        valid_weight = valid_data['weight'].to_numpy()\n",
        "        dvalid = xgb.DMatrix(valid_data.select(FEAT_COLS).to_pandas(), label=valid_data[TARGET].to_pandas(), weight=valid_weight)\n",
        "\n",
        "        # バッチサイズの指定\n",
        "        batch_size = 1000 if fold_idx == n_splits - 1 else 3000  # 最後のfoldは小さなバッチサイズ\n",
        "\n",
        "        # 学習データの作成\n",
        "        for train_idx in range(train_range[0], train_range[1], batch_size):\n",
        "            end_idx = min(train_idx + batch_size - 1, train_range[1])\n",
        "            partial_train_data = load_data(date_id_range=(train_idx, end_idx), columns=[\"date_id\", \"weight\"] + FEAT_COLS + [TARGET], return_type='pl')\n",
        "            partial_train_data = partial_train_data.with_columns([pl.col(c).cast(pl.Float32) for c in FEAT_COLS + [TARGET, \"weight\"]])\n",
        "            train_weight = partial_train_data['weight'].to_numpy()\n",
        "            dtrain = xgb.DMatrix(partial_train_data.select(FEAT_COLS).to_pandas(), label=partial_train_data[TARGET].to_pandas(), weight=train_weight)\n",
        "\n",
        "            # パラメータ設定\n",
        "            XGB_PARAMS = {\n",
        "                'objective': 'reg:squarederror',\n",
        "                'learning_rate': 0.05,\n",
        "                'max_depth': 1,\n",
        "                'min_child_weight': 3,\n",
        "                'subsample': 0.7,\n",
        "                'colsample_bytree': 0.7,\n",
        "                'random_state': 42,\n",
        "                'tree_method': 'hist',\n",
        "            }\n",
        "\n",
        "            model = xgb.train(\n",
        "                XGB_PARAMS,\n",
        "                dtrain,\n",
        "                num_boost_round=num_boost_round,\n",
        "                xgb_model=model,\n",
        "                evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
        "                early_stopping_rounds=10,\n",
        "                verbose_eval=50,\n",
        "                obj=weighted_squared_error,\n",
        "                custom_metric=weighted_rmse\n",
        "            )\n",
        "\n",
        "            # 余計なものは削除\n",
        "            del partial_train_data, dtrain, train_weight\n",
        "            gc.collect()\n",
        "\n",
        "        # R2を計算\n",
        "        y_valid_pred = model.predict(dvalid)\n",
        "        r2_score = calculate_r2(valid_data[TARGET].to_numpy(), y_valid_pred, valid_weight)\n",
        "        print(f\"Fold {fold_idx} validation R2 score: {r2_score}\")\n",
        "\n",
        "        model_group.add_model(model)\n",
        "\n",
        "        if save_models:\n",
        "            joblib.dump(model, f\"xgb_model_group_{fold_idx}.pkl\")\n",
        "            print(f\"Saved the model for fold {fold_idx} to xgb_model_group_{fold_idx}.pkl\")\n",
        "\n",
        "        del dvalid, valid_data, valid_weight, y_valid_pred\n",
        "        gc.collect()\n",
        "\n",
        "    return model_group\n",
        "\n",
        "# 実行例\n",
        "total_days = 199\n",
        "xgb_models = train_xgb_kfold(total_days=total_days, n_splits=5)\n",
        "\n",
        "#lags_ というグローバル変数を宣言し、型は Polars データフレームまたは None として定義\n",
        "lags_ : pl.DataFrame | None = None\n",
        "\n",
        "\n",
        "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
        "    \"\"\"Make a prediction.\"\"\"\n",
        "    # lags_ をグローバル変数として使用し、lags が渡されている場合は、lags_ に代入\n",
        "    global lags_\n",
        "    if lags is not None:\n",
        "        lags_ = lags\n",
        "    # test データフレームから row_id 列を選択し、responder_6 列を0で仮埋め\n",
        "    predictions = test.select(\n",
        "        'row_id',\n",
        "        pl.lit(0.0).alias('responder_6'),\n",
        "    )\n",
        "\n",
        "    # 予測値出力\n",
        "    feat = test[FEAT_COLS].to_pandas()\n",
        "    pred = xgb_models.predict(feat)\n",
        "\n",
        "    # 予測値の出力\n",
        "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
        "    print(predictions)\n",
        "\n",
        "    # The predict function must return a DataFrame\n",
        "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
        "    # with columns 'row_id', 'responder_6'\n",
        "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
        "    # and as many rows as the test data.\n",
        "    assert len(predictions) == len(test)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    inference_server.run_local_gateway(\n",
        "        (\n",
        "            '../input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
        "            '../input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "ElOLeX8ZnhW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}